{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"] = \"sk-p470K4O0CJUSbrJtUDfeSlbkFJYe4fgvqZlPTjPVMaNFe1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more the temprature value more the creative way.\n",
    "* less creative -> safer\n",
    "* more creative -> might generate wrong result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"], temperature = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text  = \"what is the capital of india\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AKSHAY KUMAR\\Documents\\projects\\LLM Project\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0, \"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moscow\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"Capital of russia\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai is a beautiful girl who loves to dance\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"write a poem about ai\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Ai, the brain of the future\n",
      "Able to think and compute with ease\n",
      "Able to learn and process data\n",
      "In a fraction of the time it would take us\n",
      "\n",
      "Ai, the power of the future\n",
      "Able to use algorithms and machine learning\n",
      "Able to take complex tasks and make them simple\n",
      "Able to make decisions quicker than we can\n",
      "\n",
      "Ai, the hope of the future\n",
      "Able to help us with the mundane\n",
      "Able to provide us with insights\n",
      "Able to make our lives easier and better\n",
      "\n",
      "Ai, the future is here\n",
      "Able to make our world a better place\n",
      "Able to be our companion and our guide\n",
      "Able to be a powerful force for good in our lives\n"
     ]
    }
   ],
   "source": [
    "output=llm.predict(\"write a poem about ai\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this India'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=['country'],template=\"Tell me the capital of this {country}\")\n",
    "\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining multiple chains using simple sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template=PromptTemplate(input_variables=['country'], template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm, prompt=capital_template)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'], template=\"Suggest me some amazing places to visit in {capital}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain=LLMChain(llm=llm, prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some of the amazing places to visit in New Delhi:\n",
      "\n",
      "1. Red Fort: Built in the 17th century, Red Fort is a magnificent red sandstone structure that stands as a symbol of India's rich cultural heritage.\n",
      "\n",
      "2. Qutub Minar: This 73-metre tall tower is a UNESCO World Heritage Site and one of the most famous landmarks in Delhi.\n",
      "\n",
      "3. India Gate: Built in 1931, India Gate is a war memorial dedicated to the Indian soldiers who died in World War I and the Afghan Wars.\n",
      "\n",
      "4. Humayun’s Tomb: This Mughal-era tomb is a UNESCO World Heritage Site and is considered to be the predecessor of the Taj Mahal.\n",
      "\n",
      "5. Jama Masjid: This is the largest and most beautiful mosque in India and is located in Old Delhi.\n",
      "\n",
      "6. Lotus Temple: This unique Bahai temple is shaped like a lotus flower and is one of the most visited structures in Delhi.\n",
      "\n",
      "7. Akshardham Temple: This beautiful Hindu temple is an architectural marvel and a must-visit for anyone who wants to experience the ancient culture and traditions of India.\n",
      "\n",
      "8. Chandni Chowk: This\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain, famous_chain])\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template=PromptTemplate(input_variables=['country'], template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm, prompt=capital_template, output_key=\"capital\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(input_variables=['capital'], template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "\n",
    "famous_chain=LLMChain(llm=llm, prompt=famous_template, output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain=SequentialChain(chains=[capital_chain, famous_chain], input_variables=['country'], output_variables=['capital', 'places'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi.',\n",
       " 'places': \" Here are some amazing places to visit in New Delhi: \\n\\n1. Red Fort: This iconic red sandstone monument was constructed in 1648 by the Mughal Emperor Shah Jahan and is a symbol of India’s rich history. \\n\\n2. India Gate: This 42-meter-high archway is a memorial to the Indian soldiers who died in World War I and is also a popular destination for tourists. \\n\\n3. Humayun's Tomb: This beautiful sandstone and marble structure was built in 1570 and is the first example of Mughal architecture in India. \\n\\n4. Qutub Minar: This 73-meter-high tower is the tallest brick minaret in the world and was built in the 13th century. \\n\\n5. Jantar Mantar: This astronomical observatory was constructed in the 18th century and is home to some of the largest sundials in the world. \\n\\n6. Lotus Temple: This unique temple shaped like a lotus flower is a Bahá’í House of Worship and is open to people of all faiths. \\n\\n7. Akshardham Temple: This stunning temple complex is one of the largest in the world\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':\"India\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charmodels with chatopenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"], temperature=0.6, model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001D200D795E0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001D200D83850>, temperature=0.6, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"I asked my AI assistant to tell me a joke about artificial intelligence, and it replied, \\'Why did the robot go on a diet? It had too many bytes!\\' Well, I guess even machines can have byte problems!\"\\n\\n2. \"You know you\\'re living in the future when you ask your AI assistant to make you a sandwich, and it replies, \\'I\\'m sorry, I\\'m not programmed for sandwich-making. But I can order you one online!\\' Looks like even AI knows its limits in the kitchen!\"\\n\\n3. \"I was chatting with my AI assistant the other day, and I asked, \\'Hey, Siri, do you believe in love at first sight?\\' And Siri responded, \\'I\\'m sorry, I can\\'t see. But I believe in love at first \\'byte\\'!\\' Well, I guess even AI can have a sense of romance!\"\\n\\n4. \"I recently got an AI assistant for my home, and I must say, it\\'s quite intelligent. It can answer all my questions, control my smart devices, and even predict the weather. But the other day, it told me, \\'I can\\'t help you with your relationship problems, but I can suggest a good therapist!\\' Talk about brutal honesty!\"\\n\\n5. \"You know you\\'ve been spending too much time with your AI assistant when you start asking it for life advice. I asked mine, \\'What\\'s the meaning of life?\\' And it replied, \\'I\\'m sorry, I can\\'t answer that. But I can tell you the airspeed velocity of an unladen swallow!\\' Well, at least it tried to lighten the existential question!\"\\n\\nRemember, comedy is subjective, so these punchlines might not resonate with everyone. Feel free to tweak them or come up with your own based on these ideas!')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"You are a comedian AI assitant\"),\n",
    "    HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promt template + LLm + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeperatedOutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. when the user gives any input you should generate five words synonyms in comma seperated\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chatllm|CommaSeperatedOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' brilliant', ' sharp', ' wise']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
